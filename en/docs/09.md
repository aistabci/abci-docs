# 9. Linux Containers

## Singularity

[Singularity](https://www.sylabs.io/singularity/) is available on the ABCI System.
Available versions are Singularity version 2.6 and SingularityPRO 3.5.
To use Singularity, set up user environment by the `module` command.

**Singularity 2.6**
```
[username@g0001~]$ module load singularity/2.6.1
```
**SingularityPRO 3.5**
```
[username@g0001~]$ module load singularitypro/3.5
```

More comprehensive user guide for Singularity will be found:

* [Singularity 2.6 User Guide](https://www.sylabs.io/guides/2.6/user-guide/)
* [SingularityPRO 3.5 User Guide](https://repo.sylabs.io/c/0f6898986ad0b646b5ce6deba21781ac62cb7e0a86a5153bbb31732ee6593f43/guides/singularitypro35-user-guide/)

To run NGC-provided Docker images on ABCI by using Singularity: [NVIDIA NGC](ngc.md)

### Running a container with Singularity

When you use Singularity, you need to start Singularity container using `singularity run` command in job script.
The container image is downloaded at first startup and cached in home area.
The second and subsequent times startup is faster by using cached data.

Example) Execution of Singularity

The following sample is execution of Singularity using caffe2 container image published in Docker Hub.
`python sample.py` is executed on Singularity container started by `singularity run` command.

**Singularity 2.6**
```
[username@es1 ~]$ qrsh -l rt_F=1 -l h_rt=1:00:00
[username@g0001~]$ module load singularity/2.6.1
[username@g0001~]$ singularity run --nv docker://caffe2ai/caffe2:latest
Docker image path: index.docker.io/caffe2ai/caffe2:latest
Cache folder set to /fs3/home/username/.singularity/docker
Creating container runtime...
...
[username@g0001~]$ python sample.py
True
```
**SingularityPRO 3.5**
```
[username@es1 ~]$ qrsh -l rt_F=1 -l h_rt=1:00:00
[username@g0001~]$ module load singularitypro/3.5
[username@g0001~]$ singularity run --nv docker://caffe2ai/caffe2:latest
...
Singularity> python sample.py
True
```

### Create a Singularity image (pull)

Singularity container image can be stored as a file.
This procedure shows how to create a Singularity image file using pull.

Example) Create a Singularity image file using `pull`

**Singularity 2.6**
```
[username@es1 ~]$ module load singularity/2.6.1
[username@es1 ~]$ singularity pull --name caffe2.img docker://caffe2ai/caffe2:latest
Docker image path: index.docker.io/caffe2ai/caffe2:latest
Cache folder set to /fs3/home/username/.singularity/docker
...
[username@es1 ~]$ ls caffe2.img
caffe2.img
```
**SingularityPRO 3.5**
```
[username@es1 ~]$ module load singularitypro/3.5
[username@es1 ~]$ singularity pull caffe2.img docker://caffe2ai/caffe2:latest
INFO:    Converting OCI blobs to SIF format
INFO:    Starting build...
...
[username@es1 ~]$ ls caffe2.img
caffe2.img
```

Example) Start a container using Singularity image file

**Singularity 2.6**
```
[username@es1 ~]$ module load singularity/2.6.1
[username@es1 ~]$ singularity run ./caffe2.img
```
**SingularityPRO 3.5**
```
[username@es1 ~]$ module load singularitypro/3.5
[username@es1 ~]$ singularity run ./caffe2.img
```

Example) Using a Singularity image file in a job script

**Singularity 2.6**
```
[username@es1 ~]$ cat job.sh
(snip)
source /etc/profile.d/modules.sh
module load singularity/2.6.1 openmpi/3.1.6

mpiexec -n 4 singularity exec --nv ./caffe2.img \
    python sample.py
```
**SingularityPRO 3.5**
```
[username@es1 ~]$ cat job.sh
(snip)
source /etc/profile.d/modules.sh
module load singularitypro/3.5 openmpi/3.1.6

mpiexec -n 4 singularity exec --nv ./caffe2.img \
    python sample.py
```

### Create a Singularity image (build)

In the SingularityPRO 3.5 environment of the ABCI system, You can build container image files using `fakeroot` option.

!!! warning
    You cannot build a container image from the recipe file in Singularity 2.6 environment.  To use your custom container image, you adapt your own server environment to the ABCI environment (the version of singularity, framework, and mpi), build a container image on it, and then move the container image to ABCI system.

Example) Create a Singularity image file using `build`

**SingularityPRO 3.5**
```
[username@es1 ~]$ module load singularitypro/3.5
[username@es1 ~]$ singularity build --fakeroot ubuntu.sif ubuntu.def
INFO:    Starting build...
(snip)
INFO:    Creating SIF file...
INFO:    Build complete: ubuntu.sif
[username@es1 singularity]$
```

If the above command is executed under the group area (/ groups1,/groups2), an error occurs. This can be avoided by executing the `newgrp` command after checking the group to which the `id -a` command belongs, as shown below, before executing the `singularity` command.  
In the example below, `gaa00000` is the group to which it belongs.

```
[username@es1 groupname]$ id -a
uid=0000(aaa00000aa) gid=0000(aaa00000aa) groups=0000(aaa00000aa),00000(gaa00000)
[username@es1 groupname]$ newgrp gaa00000
```

### Build Singularity image from Dockerfile

On ABCI, you cannot build a Singularity image directly from Dockerfile.
If you have only Dockerfile, you have two ways to build a Singularity image on ABCI.

#### Via Docker Hub {#build-via-dockerhub}

Build a Docker container image from Dockerfile on a system having Docker execution environment, and upload the image to Docker Hub. You can use the Docker container image on ABCI. 

Following example shows how to build [SSD300 v1.1 image](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD) developed by NVIDIA from Dockerfile and upload it to Docker Hub.

```
[user@pc ~]$ git clone https://github.com/NVIDIA/DeepLearningExamples
[user@pc ~]$ cd DeepLearningExamples/PyTorch/Detection/SSD
[user@pc SSD]$ cat Dockerfile
ARG FROM_IMAGE_NAME=nvcr.io/nvidia/pytorch:20.06-py3
FROM ${FROM_IMAGE_NAME}

# Set working directory
WORKDIR /workspace

ENV PYTHONPATH "${PYTHONPATH}:/workspace"

COPY requirements.txt .
RUN pip install --no-cache-dir git+https://github.com/NVIDIA/dllogger.git#egg=dllogger
RUN pip install -r requirements.txt
RUN python3 -m pip install pycocotools==2.0.0

# Copy SSD code
COPY ./setup.py .
COPY ./csrc ./csrc
RUN pip install .

COPY . .
[user@pc SSD]$ docker build -t user/docker_name .
[user@pc SSD]$ docker login && docker push user/docker_name
```

To run the built image on ABCI, please refer to [Running a container with Singularity](#running-a-container-with-singularity)

#### Convert Dockerfile to Singularity recipe

By converting Dockerfile to Singularity recipe, you can build a Singularity container image which provides the same functionality defined in the Dockerfile on ABCI.
You can manually convert Dockerfile, but using [Singularity Python](https://singularityhub.github.io/singularity-cli/) helps the conversion.

!!!warning
    The conversion of Singularity Python is not perfect.
    If `singularity build` fails when the generated Singularity recipe file is used, modify the recipe file manually.

Example procedure for installing Singularity Python)

```
[username@es1 ~]$ module load python/3.6/3.6.5
[username@es1 ~]$ python3 -m venv work
[username@es1 ~]$ source work/bin/activate
(work) [username@es1 ~]$ pip3 install spython
```

Following example shows how to modify Dockerfile of [SSD300 v1.1 image](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD) developed by NVIDIA  and convert it to Singularity recipe using Singularity Python. 

If you convert the original Dockerfile as is, the following two problems will occur at build time.
To avoid the problems, this example modifies the Dockerfile before conversion.

- No path to pip => Set the environment variable PATH to pip
- Files in WORKDIR will not be copied => Set the copy destination to the absolute path of WORKDIR

```
[username@es1 ~]$ module load python/3.6/3.6.5
[username@es1 ~]$ source work/bin/activate
(work) [username@es1 ~]$ git clone https://github.com/NVIDIA/DeepLearningExamples
(work) [username@es1 ~]$ cd DeepLearningExamples/PyTorch/Detection/SSD
(work) [username@es1 SSD]$ cp -p Dockerfile Dockerfile_org
(work) [username@es1 SSD]$ vi Dockerfile
ARG FROM_IMAGE_NAME=nvcr.io/nvidia/pytorch:20.06-py3
FROM ${FROM_IMAGE_NAME}
# Add pip Path                           <- Add
ENV PATH "/opt/conda/bin:${PATH}"        <- Add
# Set working directory
WORKDIR /workspace
ENV PYTHONPATH "${PYTHONPATH}:/workspace"
COPY requirements.txt /workspace         <- Change path
RUN pip install --no-cache-dir git+https://github.com/NVIDIA/dllogger.git#egg=dllogger
RUN pip install -r requirements.txt
RUN python3 -m pip install pycocotools==2.0.0
# Copy SSD code
COPY ./setup.py /workspace               <- Change path
COPY ./csrc /workspace/csrc              <- Change path
RUN pip install .
COPY . /workspace                        <- Change path
(work) [username@es1 SSD]$ spython recipe Dockerfile ssd.def
```

To create a Singularity image from the generated recipe file on ABCI, please refer to [Create a Singularity image (build)](#create-a-singularity-image-build).

## Docker

In the ABCI System, job can be executed on Docker container.
When you use Docker, you need to set up user environment by the `module` command and specify `-l docker` option and `-l docker_image` option at job submission.

!!! warning
    Docker container can not be used on memory-intensive node in the ABCI system.

| option | description |
|:--|:--|
| -l docker | job is executed on Docker container |
| -l docker_images | specify using Docker image |

The available Docker image can be referred by `show_docker_images` command.

```
[username@es1 ~]$ show_docker_images
REPOSITORY                TAG             IMAGE ID     CREATED       SIZE
jcm:5000/dhub/ubuntu      latest          113a43faa138 3 weeks ago   81.2MB
```

!!! warning
    In the ABCI System, Users can use only Docker images provided in the system.

Example) job script using Docker

The following job script executes `python3 ./test.py` on Docker container.

```
[username@es1 ~]$ cat run.sh
#!/bin/sh
#$-cwd
#$-j y
#$-l rt_F=1
#$-l docker=1
#$-l docker_images="*jcm:5000/dhub/ubuntu*"

python3 ./sample.py
```

Example) Submission of job script using Docker

```
[username@es1 ~]$ qsub run.sh
Your job 12345 ("run.sh") has been submitted
```

!!! warning
    Docker container is only available on a node-exclusive job.

